# YOLOv5 Model Export Pipeline

A complete, production-ready pipeline for training, exporting, and deploying YOLOv5 object detection models with ONNX support.

## ğŸ¯ Overview

This repository provides a structured workflow for:
- Training YOLOv5 models on custom datasets
- Exporting models to ONNX format (opset 17+)
- Running optimized inference with latency benchmarking
- Deploying models in production environments

## ğŸ“ Repository Structure

```
yolov5-model-export/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/              # Data processing utilities
â”‚   â”œâ”€â”€ models/            # Model export scripts
â”‚   â”œâ”€â”€ training/          # Training scripts
â”‚   â”œâ”€â”€ inference/         # Inference scripts
â”‚   â””â”€â”€ utils/             # Helper utilities
â”œâ”€â”€ configs/               # Configuration files
â”‚   â”œâ”€â”€ config.yaml        # Main configuration
â”‚   â””â”€â”€ train_config.yaml  # Training configuration
â”œâ”€â”€ scripts/               # Automation scripts
â”‚   â”œâ”€â”€ setup.sh          # Environment setup
â”‚   â”œâ”€â”€ train.sh          # Training script
â”‚   â”œâ”€â”€ export.sh         # Model export
â”‚   â”œâ”€â”€ infer.sh          # Inference script
â”‚   â”œâ”€â”€ benchmark.sh      # Benchmarking
â”‚   â””â”€â”€ run_pipeline.sh   # Complete pipeline
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ DATA_CARD.md      # Dataset documentation
â”‚   â”œâ”€â”€ EVALUATION.md     # Evaluation report
â”‚   â””â”€â”€ DEPLOYMENT.md     # Deployment guide
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ models/           # Trained model weights
â”‚   â””â”€â”€ exports/          # Exported ONNX models
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw data
â”‚   â”œâ”€â”€ processed/        # Processed data
â”‚   â””â”€â”€ sample/           # Sample data
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ Dockerfile            # Docker container definition
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ environment.yml       # Conda environment
â””â”€â”€ README.md            # This file
```

## ğŸš€ Quick Start

### Option 1: Complete Pipeline (Recommended)

Run the entire pipeline with a single command:

```bash
bash scripts/run_pipeline.sh
```

This will:
1. Set up the environment
2. Train the model
3. Export to ONNX
4. Run inference

### Option 2: Step-by-Step

#### 1. Setup Environment

```bash
# Using pip
pip install -r requirements.txt
bash scripts/setup.sh

# Using conda
conda env create -f environment.yml
conda activate yolov5-export
bash scripts/setup.sh
```

#### 2. Train Model

```bash
bash scripts/train.sh
```

Training artifacts will be saved to `runs/train/exp/`.

#### 3. Export to ONNX

```bash
bash scripts/export.sh runs/train/exp/weights/best.pt
```

The ONNX model will be saved alongside the weights file.

#### 4. Run Inference

```bash
bash scripts/infer.sh \
    runs/train/exp/weights/best.onnx \
    data/coco128/images/train2017/000000000009.jpg
```

#### 5. Benchmark Performance

```bash
bash scripts/benchmark.sh \
    runs/train/exp/weights/best.onnx \
    data/coco128/images/train2017/000000000009.jpg \
    100
```

## ğŸ³ Docker Usage

### Build Image

```bash
docker build -t yolov5-export:latest .
```

### Run Container

```bash
docker run -it --rm \
    --gpus all \
    -v $(pwd)/data:/workspace/data \
    -v $(pwd)/artifacts:/workspace/artifacts \
    yolov5-export:latest \
    bash scripts/run_pipeline.sh
```

## ğŸ“Š Model Performance

### Training Results
- Dataset: COCO128
- Model: YOLOv5s
- Epochs: 3
- Batch Size: 16
- Image Size: 640x640

### Inference Latency (GPU)
- Mean: ~266 ms
- P95: ~280 ms
- P99: ~290 ms

See [EVALUATION.md](docs/EVALUATION.md) for detailed metrics.

## ğŸ“ Configuration

Edit `configs/config.yaml` to customize:
- Model architecture
- Training hyperparameters
- Export settings
- Inference parameters

## ğŸ”§ Development

### Running Tests

```bash
pytest tests/
```

### Code Formatting

```bash
black src/
flake8 src/
```

## ğŸ“š Documentation

- [Data Card](docs/DATA_CARD.md) - Dataset documentation
- [Evaluation Report](docs/EVALUATION.md) - Model performance metrics
- [Deployment Guide](docs/DEPLOYMENT.md) - Production deployment instructions

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [Ultralytics YOLOv5](https://github.com/ultralytics/yolov5) - Base model implementation
- [COCO Dataset](https://cocodataset.org/) - Training dataset

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact [www.linkedin.com/in/arniteshkumar].

## E-Mail: arniteshkumar@gmail.com

- [YOLOv5 Documentation](https://docs.ultralytics.com/)
- [ONNX Runtime](https://onnxruntime.ai/)
- [PyTorch](https://pytorch.org/)
