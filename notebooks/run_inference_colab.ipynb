{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 Unified Inference — Google Colab\n",
    "Runs **PyTorch** and **ONNX** inference side-by-side on COCO val2017.\n",
    "\n",
    "Features:\n",
    "- Bounding-box images saved to `results/bbox_outputs/`\n",
    "- Class labels + confidence scores\n",
    "- MSE baseline comparison (PyTorch ↔ ONNX raw logits)\n",
    "- mAP@0.5 accuracy metrics for both backends\n",
    "\n",
    "**Set your GitHub PAT below, then Run All.**"
   ],
   "id": "md-intro"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 0. Configuration ───────────────────────────────────────────────────────\n",
    "GITHUB_TOKEN = \"YOUR_GITHUB_PAT_HERE\"   # <-- paste your token\n",
    "REPO_OWNER   = \"ARNiteshKumar\"\n",
    "REPO_NAME    = \"MAGIC-Cluster_YoLoV5\"\n",
    "BRANCH       = \"claude/yolov5-coco-validation-oToNk\"\n",
    "\n",
    "# Model weights — set to None to skip that backend\n",
    "PT_WEIGHTS   = \"yolov5s.pt\"       # download below if missing\n",
    "ONNX_WEIGHTS = \"yolov5s.onnx\"     # exported from PT weights below\n",
    "\n",
    "# Evaluation settings\n",
    "NUM_EVAL_IMAGES = 200    # set to 5000 for full COCO val run (slow on CPU)\n",
    "SAVE_VIS        = 20     # save annotated images for first N val images\n",
    "CONF_THRESH     = 0.25\n",
    "IOU_THRESH      = 0.45\n",
    "DEVICE          = \"cpu\"  # or 'cuda'"
   ],
   "id": "cell-config"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. Clone / pull the repo ───────────────────────────────────────────────\n",
    "import os\n",
    "\n",
    "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n",
    "\n",
    "if not os.path.isdir(REPO_NAME):\n",
    "    !git clone --branch {BRANCH} {REPO_URL}\n",
    "else:\n",
    "    !git -C {REPO_NAME} pull origin {BRANCH}\n",
    "\n",
    "%cd {REPO_NAME}\n",
    "print(\"Working dir:\", os.getcwd())"
   ],
   "id": "cell-clone"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 2. Install dependencies ────────────────────────────────────────────────\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Clone YOLOv5 helper repo (provides model classes)\n",
    "if not os.path.isdir('yolov5'):\n",
    "    !git clone -q https://github.com/ultralytics/yolov5\n",
    "    !pip install -q -r yolov5/requirements.txt"
   ],
   "id": "cell-deps"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 3. Download YOLOv5s weights + export to ONNX ──────────────────────────\n",
    "import torch\n",
    "\n",
    "# Download pretrained YOLOv5s\n",
    "if not os.path.isfile(PT_WEIGHTS):\n",
    "    torch.hub.download_url_to_file(\n",
    "        'https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt',\n",
    "        PT_WEIGHTS\n",
    "    )\n",
    "    print(f\"Downloaded {PT_WEIGHTS}\")\n",
    "\n",
    "# Export to ONNX\n",
    "if not os.path.isfile(ONNX_WEIGHTS):\n",
    "    !python yolov5/export.py \\\n",
    "        --weights {PT_WEIGHTS} \\\n",
    "        --include onnx \\\n",
    "        --opset 17 \\\n",
    "        --simplify \\\n",
    "        --imgsz 640\n",
    "    # export.py writes alongside .pt\n",
    "    onnx_src = PT_WEIGHTS.replace('.pt', '.onnx')\n",
    "    if os.path.isfile(onnx_src) and onnx_src != ONNX_WEIGHTS:\n",
    "        os.rename(onnx_src, ONNX_WEIGHTS)\n",
    "    print(f\"Exported {ONNX_WEIGHTS}\")"
   ],
   "id": "cell-weights"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 4. Download COCO val2017 subset (first NUM_EVAL_IMAGES via fiftyone) ──\n",
    "# Using fiftyone for fast partial download — avoids the full 1 GB zip\n",
    "!pip install -q fiftyone\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    max_samples=NUM_EVAL_IMAGES,\n",
    "    dataset_name=\"coco-val-subset\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Symlink into expected directory layout\n",
    "import shutil, pathlib\n",
    "\n",
    "coco_img_dir  = pathlib.Path(\"data/coco/images/val2017\")\n",
    "coco_ann_dir  = pathlib.Path(\"data/coco/annotations\")\n",
    "coco_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "coco_ann_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export annotations\n",
    "dataset.export(\n",
    "    export_dir=\"data/coco\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Move images into val2017/\n",
    "for fp in pathlib.Path(\"data/coco/data\").glob(\"*.jpg\"):\n",
    "    shutil.copy(str(fp), str(coco_img_dir / fp.name))\n",
    "\n",
    "# Rename annotation file\n",
    "ann_src = pathlib.Path(\"data/coco/labels.json\")\n",
    "ann_dst = coco_ann_dir / \"instances_val2017.json\"\n",
    "if ann_src.is_file() and not ann_dst.is_file():\n",
    "    shutil.copy(str(ann_src), str(ann_dst))\n",
    "\n",
    "print(f\"COCO subset ready: {len(list(coco_img_dir.glob('*.jpg')))} images\")"
   ],
   "id": "cell-coco"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 5. Single-image quick test ─────────────────────────────────────────────\n",
    "sample_img = next(pathlib.Path(\"data/coco/images/val2017\").glob(\"*.jpg\"))\n",
    "\n",
    "!python src/inference/infer.py \\\n",
    "    --pt-weights   {PT_WEIGHTS} \\\n",
    "    --onnx-weights {ONNX_WEIGHTS} \\\n",
    "    --image        {sample_img} \\\n",
    "    --conf         {CONF_THRESH} \\\n",
    "    --iou          {IOU_THRESH} \\\n",
    "    --device       {DEVICE} \\\n",
    "    --output-dir   results/bbox_outputs"
   ],
   "id": "cell-single"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6. Display bbox output images ─────────────────────────────────────────\n",
    "from IPython.display import display, Image as IPImage\n",
    "import pathlib\n",
    "\n",
    "out_imgs = sorted(pathlib.Path(\"results/bbox_outputs\").glob(\"*.jpg\"))[:6]\n",
    "for p in out_imgs:\n",
    "    print(p.name)\n",
    "    display(IPImage(str(p), width=640))"
   ],
   "id": "cell-display"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 7. Full COCO evaluation (PyTorch + ONNX mAP, MSE comparison) ──────────\n",
    "!python src/inference/infer.py \\\n",
    "    --pt-weights       {PT_WEIGHTS} \\\n",
    "    --onnx-weights     {ONNX_WEIGHTS} \\\n",
    "    --eval \\\n",
    "    --coco-dir         data/coco \\\n",
    "    --num-eval-images  {NUM_EVAL_IMAGES} \\\n",
    "    --save-vis         {SAVE_VIS} \\\n",
    "    --conf             {CONF_THRESH} \\\n",
    "    --iou              {IOU_THRESH} \\\n",
    "    --device           {DEVICE} \\\n",
    "    --output-dir       results/bbox_outputs"
   ],
   "id": "cell-eval"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 8. Show evaluation bbox samples ───────────────────────────────────────\n",
    "out_imgs = sorted(pathlib.Path(\"results/bbox_outputs\").glob(\"*.jpg\"))[:10]\n",
    "for p in out_imgs:\n",
    "    print(p.name)\n",
    "    display(IPImage(str(p), width=640))"
   ],
   "id": "cell-show-eval"
  }
 ]
}
