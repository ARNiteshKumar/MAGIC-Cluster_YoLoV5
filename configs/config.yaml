# YOLOv5 Model Export Configuration

model:
  name: yolov5s
  weights: yolov5s.pt
  architecture: yolov5
  
training:
  dataset: coco128
  img_size: 640
  batch_size: 16
  epochs: 3
  device: 0  # GPU device, or 'cpu'
  workers: 8
  cache: true
  
export:
  format: onnx
  opset: 17
  dynamic: false
  simplify: true
  img_size: 640
  
inference:
  conf_threshold: 0.25
  iou_threshold: 0.45
  max_detections: 1000
  device: cpu
  img_size: 640
  # Output folder for annotated bounding-box images
  bbox_output_dir: ./results/bbox_outputs
  # Number of COCO val images to run during evaluation (0 = all 5000)
  num_eval_images: 5000
  # Number of annotated images to save during COCO eval run
  save_vis: 50

evaluation:
  # Full COCO val2017 dataset path
  coco_dir: ./data/coco
  # Metrics to report
  metrics:
    - mAP@0.5
    - mAP@0.5:0.95
    - precision
    - recall
    - latency_ms
  # MSE comparison between PyTorch and ONNX raw outputs
  mse_comparison: true

paths:
  data_dir: ./data
  weights_dir: ./artifacts/models
  export_dir: ./artifacts/exports
  results_dir: ./results
  bbox_outputs: ./results/bbox_outputs